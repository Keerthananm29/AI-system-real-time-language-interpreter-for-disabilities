{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f85af88b-4ef5-4663-a271-2a60a42377ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils.class_weight import compute_class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "094b9ef8-cfbe-4893-8a36-f3e30cdfa44c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Configuration ===\n",
    "DATA_DIR = 'words_dataset'\n",
    "images_per_class = 300\n",
    "\n",
    "# === Load only valid class folders ===\n",
    "LABELS = sorted([d for d in os.listdir(DATA_DIR) if os.path.isdir(os.path.join(DATA_DIR, d))])\n",
    "LABEL_TO_INDEX = {label: idx for idx, label in enumerate(LABELS)}\n",
    "NUM_CLASSES = len(LABELS)\n",
    "\n",
    "# === MediaPipe Setup ===\n",
    "mp_hands = mp.solutions.hands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "797f4ff6-58ff-4ccc-b0f0-e37aaab1d8b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_landmarks(image_path):\n",
    "    image = cv2.imread(image_path)\n",
    "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    with mp_hands.Hands(static_image_mode=True) as hands:\n",
    "        result = hands.process(image_rgb)\n",
    "        if result.multi_hand_landmarks:\n",
    "            landmarks = []\n",
    "            for lm in result.multi_hand_landmarks[0].landmark:\n",
    "                landmarks.extend([lm.x, lm.y, lm.z])\n",
    "            return landmarks\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "393d7761-9e5d-41f7-8299-a3430c500dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset():\n",
    "    X, y = [], []\n",
    "    for label in LABELS:\n",
    "        label_dir = os.path.join(DATA_DIR, label)\n",
    "        count = 0\n",
    "        for img_name in os.listdir(label_dir):\n",
    "            img_path = os.path.join(label_dir, img_name)\n",
    "            try:\n",
    "                landmarks = extract_landmarks(img_path)\n",
    "                if landmarks:\n",
    "                    X.append(landmarks)\n",
    "                    y.append(LABEL_TO_INDEX[label])\n",
    "                    count += 1\n",
    "                if count >= images_per_class:\n",
    "                    break\n",
    "            except Exception as e:\n",
    "                print(f\"Error in {img_path}: {e}\")\n",
    "    return np.array(X), to_categorical(y, NUM_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d7b5ba6-bdb8-43f2-99c0-522f7d89bed2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n"
     ]
    }
   ],
   "source": [
    "# === Load and split data ===\n",
    "print(\"Loading data...\")\n",
    "X, y = load_dataset()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3311442d-6be9-415f-8ae3-38fb32706c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Compute class weights ===\n",
    "y_int = np.argmax(y_train, axis=1)\n",
    "class_weights = compute_class_weight('balanced', classes=np.unique(y_int), y=y_int)\n",
    "class_weights_dict = dict(enumerate(class_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8955f07f-10a3-4aba-b2c7-65270d1cbc85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model\n",
    "model = Sequential([\n",
    "    Dense(128, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    Dropout(0.3),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(NUM_CLASSES, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5174470d-8c84-4de6-a78b-fc21a27410b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model...\n",
      "Epoch 1/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9579 - loss: 0.1576 - val_accuracy: 0.9793 - val_loss: 0.0783\n",
      "Epoch 2/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9574 - loss: 0.1467 - val_accuracy: 0.9799 - val_loss: 0.0765\n",
      "Epoch 3/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9606 - loss: 0.1458 - val_accuracy: 0.9770 - val_loss: 0.0835\n",
      "Epoch 4/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9560 - loss: 0.1550 - val_accuracy: 0.9822 - val_loss: 0.0707\n",
      "Epoch 5/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9534 - loss: 0.1824 - val_accuracy: 0.9767 - val_loss: 0.0881\n",
      "Epoch 6/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9599 - loss: 0.1377 - val_accuracy: 0.9816 - val_loss: 0.0723\n",
      "Epoch 7/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9573 - loss: 0.1507 - val_accuracy: 0.9796 - val_loss: 0.0760\n",
      "Epoch 8/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9620 - loss: 0.1327 - val_accuracy: 0.9814 - val_loss: 0.0704\n",
      "Epoch 9/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9591 - loss: 0.1412 - val_accuracy: 0.9812 - val_loss: 0.0753\n",
      "Epoch 10/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9609 - loss: 0.1373 - val_accuracy: 0.9813 - val_loss: 0.0742\n",
      "Epoch 11/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9611 - loss: 0.1384 - val_accuracy: 0.9814 - val_loss: 0.0692\n",
      "Epoch 12/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9613 - loss: 0.1371 - val_accuracy: 0.9834 - val_loss: 0.0675\n",
      "Epoch 13/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9614 - loss: 0.1369 - val_accuracy: 0.9753 - val_loss: 0.0786\n",
      "Epoch 14/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9623 - loss: 0.1337 - val_accuracy: 0.9812 - val_loss: 0.0707\n",
      "Epoch 15/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9622 - loss: 0.1258 - val_accuracy: 0.9836 - val_loss: 0.0675\n",
      "Epoch 16/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9620 - loss: 0.1325 - val_accuracy: 0.9833 - val_loss: 0.0637\n",
      "Epoch 17/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9650 - loss: 0.1226 - val_accuracy: 0.9838 - val_loss: 0.0641\n",
      "Epoch 18/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9633 - loss: 0.1276 - val_accuracy: 0.9845 - val_loss: 0.0648\n",
      "Epoch 19/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9634 - loss: 0.1701 - val_accuracy: 0.9802 - val_loss: 0.0681\n",
      "Epoch 20/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9610 - loss: 0.1568 - val_accuracy: 0.9828 - val_loss: 0.0650\n",
      "Epoch 21/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9629 - loss: 0.1295 - val_accuracy: 0.9823 - val_loss: 0.0697\n",
      "Epoch 22/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9635 - loss: 0.1283 - val_accuracy: 0.9860 - val_loss: 0.0583\n",
      "Epoch 23/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9629 - loss: 0.1381 - val_accuracy: 0.9808 - val_loss: 0.0679\n",
      "Epoch 24/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9602 - loss: 0.1406 - val_accuracy: 0.9846 - val_loss: 0.0637\n",
      "Epoch 25/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9652 - loss: 0.1228 - val_accuracy: 0.9832 - val_loss: 0.0655\n",
      "Epoch 26/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9635 - loss: 0.1248 - val_accuracy: 0.9697 - val_loss: 0.0894\n",
      "Epoch 27/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9645 - loss: 0.1251 - val_accuracy: 0.9823 - val_loss: 0.0671\n",
      "Epoch 28/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9639 - loss: 0.1295 - val_accuracy: 0.9813 - val_loss: 0.0689\n",
      "Epoch 29/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9645 - loss: 0.1278 - val_accuracy: 0.9836 - val_loss: 0.0669\n",
      "Epoch 30/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9652 - loss: 0.1219 - val_accuracy: 0.9767 - val_loss: 0.0773\n",
      "Epoch 31/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9644 - loss: 0.1260 - val_accuracy: 0.9818 - val_loss: 0.0654\n",
      "Epoch 32/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9684 - loss: 0.1165 - val_accuracy: 0.9820 - val_loss: 0.0648\n",
      "Epoch 33/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9652 - loss: 0.1231 - val_accuracy: 0.9796 - val_loss: 0.0714\n",
      "Epoch 34/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9651 - loss: 0.1181 - val_accuracy: 0.9774 - val_loss: 0.0757\n",
      "Epoch 35/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9653 - loss: 0.1274 - val_accuracy: 0.9857 - val_loss: 0.0559\n",
      "Epoch 36/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9695 - loss: 0.1091 - val_accuracy: 0.9810 - val_loss: 0.0695\n",
      "Epoch 37/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9659 - loss: 0.1201 - val_accuracy: 0.9848 - val_loss: 0.0575\n",
      "Epoch 38/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9644 - loss: 0.1767 - val_accuracy: 0.9817 - val_loss: 0.0651\n",
      "Epoch 39/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9664 - loss: 0.1312 - val_accuracy: 0.9816 - val_loss: 0.0658\n",
      "Epoch 40/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9648 - loss: 0.1219 - val_accuracy: 0.9840 - val_loss: 0.0604\n",
      "Epoch 41/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9641 - loss: 0.2621 - val_accuracy: 0.9840 - val_loss: 0.0596\n",
      "Epoch 42/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9668 - loss: 0.1155 - val_accuracy: 0.9814 - val_loss: 0.0670\n",
      "Epoch 43/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9698 - loss: 0.1145 - val_accuracy: 0.9839 - val_loss: 0.0569\n",
      "Epoch 44/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9670 - loss: 0.1154 - val_accuracy: 0.9814 - val_loss: 0.0626\n",
      "Epoch 45/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9677 - loss: 0.1162 - val_accuracy: 0.9780 - val_loss: 0.0747\n",
      "Epoch 46/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9609 - loss: 0.1356 - val_accuracy: 0.9828 - val_loss: 0.0676\n",
      "Epoch 47/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9665 - loss: 0.1191 - val_accuracy: 0.9860 - val_loss: 0.0550\n",
      "Epoch 48/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9689 - loss: 0.1146 - val_accuracy: 0.9841 - val_loss: 0.0600\n",
      "Epoch 49/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9675 - loss: 0.1138 - val_accuracy: 0.9850 - val_loss: 0.0585\n",
      "Epoch 50/50\n",
      "\u001b[1m1596/1596\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9663 - loss: 0.1167 - val_accuracy: 0.9842 - val_loss: 0.0608\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1933a869df0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "print(\"Training model...\")\n",
    "model.fit(X_train, y_train, epochs=50, validation_data=(X_test, y_test), class_weight=class_weights_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1bff27c3-99a4-4320-89f4-94656ae0662a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model trained and saved successfully.\n"
     ]
    }
   ],
   "source": [
    "# Save model\n",
    "os.makedirs('model', exist_ok=True)\n",
    "model.save('model/asl_cnn_model.h5')\n",
    "print(\"✅ Model trained and saved successfully.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
